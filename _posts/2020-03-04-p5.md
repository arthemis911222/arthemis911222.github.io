---
layout: post
title: "KINME配置大数据平台：问题记录和解决方法"
subtitle: 'KNIME连接Hadoop、Spark、Hive过程中会遇到很多问题，这里将问题和解决方案记录下，方便后续少踩坑。'
date: 2020-03-05 12:00:00
author: "Jiajie Wu"
header-style: text
catalog: true
tags:
  - KNIME
  - Big Data
  - Spark
  - Hadoop
  - Hive
---

KNIME作为一个功能完善的可视化数据工作流平台，支持连接到Hadoop、Spark、Hive等大数据平台进行数据分析。

在进行相关的实验前，需要部署好相应的大数据平台并将KNIME和它们连接起来，这个过程中会出现很多问题，往往会耗费很多的时间和精力。为了防止下次再遇到相同的问题，在此记录一下。

---

<html>
<p>
KNIME版本：3.7<br/>
Hadoop版本：2.6<br/>
Spark版本：2.4<br/>
Hive版本：2.3<br/>
</p>
</html>

由于KNIME官网说明支持的版本是到2.x，所以没有选择最新3.x版本的Hadoop和Spark（3.x版本是否可行还未检验）。

第一部分介绍KNIME连接容器化大数据平台（Hadoop、Spark）的尝试，以及问题的猜测总结。因为最后还是失败了，所以不感兴趣的可以跳过。

第二部分，KNIME连接Hadoop需要注意的。

第三部分，KNIME连接Spark需要注意的。

第四部分，KNIME连接Hive需要注意的。

### 容器化的尝试

首次尝试容器化，遇到通过KNIME的「Down」和「Upload」节点从HDFS上传和下载文件失败。原因是KNIME无法访问容器内的DataNode的50075端口。

开启容器的端口映射，修改hosts文件将master映射为主机地址，网页可访问50075端口。但是报错显示KNIME节点依然无法访问。根据日志显示，KNIME访问的依然是容器ip+50075端口，而非主机ip+50075端口。

<html>
<font color='#FF6600'>猜测原因：容器镜像来自网络源，hadoop配置文件默认使用localhost作为访问地址。</font>
<p></p>
<font color='#FF6600'>
ps：容器化的hadoop集群一般会将多个容器的50075映射为主机的5007x端口，印象中KNIME似乎默认了只有50075端口，所以比起单容器的standalone模式，多容器的cluster模式大概率不会成功（未明确验证）
</font>

</html>

### KNIME和Hadoop

**<u>KNIME和Hadoop必须在同一网络，KNIME必须能直接访问Hadoop集群所有节点的ip（特别是DataNode）。</u>**

**· 报错1：**

Hadoop集群本身没问题，KNIME能连接到Hadoop，但是上传和下载文件失败。

```
Execute failed: Could not obtain block: BP-1241294268-172.18.0.2-1582721289508:blk_1073741830_1006 file=/knime/README.txt
```

解决方式：错误信息显示，DataNode节点的地址为“172.18.0.2”，而KNIME无法直接访问该地址。查看配置文件”core-site.xml”和“hdfs-site.xml”，确定KNIME所在的机器能够访问该地址。


**· 报错2：**

在本机MAC电脑上部署Hadoop，网页方式能访问，控制台操作也正常，但通过KNIME就是无法连接成功。

```
Call From wingdeMacBook-Air.local/192.168.1.95 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused;
```

解决方式：放弃本机部署，改为在服务器上部署。

---
附上参考用的配置文件：

根据实际情况，修改localhost为对应的ip地址。

core-site.xml：

```
<property>
<name>fs.defaultFS</name>
<value>hdfs://localhost:9000</value>
</property>
<property>
<name>hadoop.tmp.dir</name>
<value>file:/root/hadoop/tmp</value>
<description>Abase for other temporary directories.</description>
</property>
```

hdfs-site.xml:

```
<property>
<name>dfs.namenode.secondary.http-address</name>
<value>localhost:50090</value>
</property>
<property>
<name>dfs.replication</name>
<value>1</value>
</property>
<property>
<name>dfs.namenode.name.dir</name>
<value>file:/root/hadoop/tmp/dfs/name</value>
</property>
<property>
<name>dfs.datanode.data.dir</name>
<value>file:/root/hadoop/tmp/dfs/data</value>
</property>

```

### KNIME和Spark

**<u>需要部署sparkjobserver。因为官方提供的文档都只包含在linux环境下的设置，在windows和mac上可能会失败。</u>**

**· 报错1：**

SparkContext连接成功，无明显报错，但执行某些任务长时间等待，无响应。

```
2020-02-27 03:00:55,199 : DEBUG : KNIME-Worker-31 : LocalNodeExecutionJob : Spark Category To Number : 4:196 : Spark Category To Number 4:196 Start execute
2020-02-27 03:00:55,208 : DEBUG : KNIME-Worker-31 : JobserverJobController : Spark Category To Number : 4:196 : Submitting Spark job: org.knime.bigdata.spark2_4.jobs.preproc.convert.category2number.Category2NumberJob
2020-02-27 03:00:55,339 : DEBUG : KNIME-Worker-31 : JobserverJobController : Spark Category To Number : 4:196 : Start waiting for job...
2020-02-27 03:00:55,373 : DEBUG : KNIME-Worker-31 : JobserverJobController : Spark Category To Number : 4:196 : Polling status of job: 8cf4d2f3-5a0f-45f5-97fb-12e7c0ad254f
2020-02-27 03:00:55,529 : DEBUG : KNIME-Worker-31 : JobserverJobController : Spark Category To Number : 4:196 : Polling status of job: 8cf4d2f3-5a0f-45f5-97fb-12e7c0ad254f
……
```

解决方式：启动了master，但没有启动work。启动work，解决。

---

**附件：**[sparkjobserver配置文档](https://raw.githubusercontent.com/arthemis911222/arthemis911222.github.io/master/postfile/file/p5-knime-spark.pdf)


### KNIME和Hive

**<u>部署完后，需要启动远程访问的服务“hiveserver2”，端口默认10000。</u>**

**· 报错1：**

启动hiveserver2后，没有错误信息打印出，后台有进程启动，但10000端口没有开启。

解决方法：
关闭hiveserver2，修改启动hiveserver2的指令为下面的形式，将错误信息在控制台输出。
```
hive --service hiveserver2 --hiveconf hive.server2.thrift.port=10000 --hiveconf hive.root.logger=INFO,console
```

根据输出的错误信息，发现是之前启动失败，hive的目录下已经生成了metastore文件夹，再起启动后存在冲突。之后的报错基本都是相同的原因，根据错误日志，删除有冲突的旧文件。重启hiveserver2，成功！

**· 报错2：**

```
Failed to open new session: java.lang.RuntimeException:
org.apache.hadoop.ipc.RemoteException
(org.apache.hadoop.security.authorize.AuthorizationException):
User: root is not allowed to impersonate hue
```

解决方式：修改hadoop的core-site.xml文件，添加下面这一段——

```
<property>
  <name>hadoop.proxyuser.root.groups</name>
  <value>*</value>
</property>
<property>
  <name>hadoop.proxyuser.root.hosts</name>
  <value>*</value>
</property>
```

**· 报错3：**

```
Different HDFS and database user root/hive found, this might result in permission problems.
```

解决方式：修改hadoop和hive的配置文件，将hadoop的用户和hive数据库的用户设置为同一个。

---
ps：第一次部署Hive的时候，出过其他错误，最后通过将hadoop的core-site.xml和hdfs-site.xml文件复制到Hive的配置文件夹下解决。这次没有出现过类似问题，但还是在此记录一下。

### 总结和后记

1. 虽然两次容器部署都失败了，但是每一次都有新的进展。这里做一下记录，总结问题所在。
2. 问题出现并解决后需要及时记录，否则下次出现同样问题就会浪费更多时间。（很多时候，在问题解决的那一刻，因为忽然觉得也不是什么大问题，往往就会选择不记录）

-END-
